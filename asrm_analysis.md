# ğŸ” ASRMæ¨¡å—é—®é¢˜æ·±åº¦åˆ†æ

## ğŸ“– **åŒé‡å¯¹æ¯”å­¦ä¹ (DCL)ä¸ASRMçš„ç†è®ºå·®å¼‚**

### DCLæ–¹æ³•çš„æ ¸å¿ƒæœºåˆ¶
```
DCL = è‡ªç›‘ç£å¯¹æ¯”å­¦ä¹  + ç›‘ç£å¯¹æ¯”å­¦ä¹  + ç„¦ç‚¹æŸå¤±
ç›®æ ‡: æ•è·span-levelä¿¡æ¯ï¼Œè¶…è¶Štoken-levelè¯­ä¹‰
```

### æ‚¨çš„ASRMè®¾è®¡åˆè¡·
```
ASRM = æ³¨æ„åŠ›å¼•å¯¼çš„è¯­ä¹‰æ ¡å‡†
ç›®æ ‡: è§£å†³å¯¹æ¯”å­¦ä¹ ä¸­dropoutçš„é—®é¢˜
```

## ğŸš¨ **ASRMä¸èµ·ä½œç”¨çš„æ ¹æœ¬åŸå› **

### 1. **è¯­ä¹‰å±‚æ¬¡ä¸åŒ¹é…**

**DCLå…³æ³¨çš„æ˜¯span-levelè¯­ä¹‰**ï¼š
- æ•è·è¯æ±‡ç»„åˆçš„è¯­ä¹‰
- ç†è§£ä¸Šä¸‹æ–‡ä¸­çš„è¯­ä¹‰å…³ç³»
- è¯†åˆ«éšå«çš„ä»‡æ¨æ„å›¾

**ASRMå…³æ³¨çš„æ˜¯token-levelæ ¡å‡†**ï¼š
- å¯¹å•ä¸ªtokenè¿›è¡Œé‡è¦æ€§åŠ æƒ
- å…¨å±€å¹³å‡æ± åŒ–ä¸¢å¤±äº†å±€éƒ¨è¯­ä¹‰ç»“æ„
- æ— æ³•æ•è·span-levelçš„è¯­ä¹‰ç»„åˆ

### 2. **ä¿¡æ¯å‹ç¼©è¿‡åº¦**

```python
# åŸå§‹ASRMçš„é—®é¢˜
z = torch.mean(x, dim=1)  # å…¨å±€å¹³å‡ - ä¸¢å¤±ä½ç½®ä¿¡æ¯
s = self.excitation(z)    # å‹ç¼©åˆ°æ ‡é‡æƒé‡
enhanced_x = x * s_expanded  # æ‰€æœ‰ä½ç½®ä½¿ç”¨ç›¸åŒæƒé‡
```

**é—®é¢˜**ï¼š
- å…¨å±€å¹³å‡æ± åŒ–æŠ¹å¹³äº†åºåˆ—ä¸­çš„ä½ç½®å·®å¼‚
- æ‰€æœ‰tokenä½¿ç”¨ç›¸åŒçš„æ ¡å‡†æƒé‡
- æ— æ³•åŒºåˆ†å…³é”®spanå’Œæ™®é€štoken

### 3. **ä¸å¯¹æ¯”å­¦ä¹ ç›®æ ‡å†²çª**

**å¯¹æ¯”å­¦ä¹ éœ€è¦**ï¼š
- ä¿æŒè¯­ä¹‰å¤šæ ·æ€§
- å¢å¼ºåˆ¤åˆ«æ€§ç‰¹å¾
- æ‹‰è¿‘ç›¸ä¼¼æ ·æœ¬ï¼Œæ¨è¿œä¸åŒæ ·æœ¬

**ASRMå®é™…æ•ˆæœ**ï¼š
- ç»Ÿä¸€åŒ–æ‰€æœ‰tokençš„é‡è¦æ€§
- å‡å°‘äº†ç‰¹å¾çš„å¤šæ ·æ€§
- å¯èƒ½å‰Šå¼±äº†åˆ¤åˆ«æ€§ä¿¡æ¯

## ğŸ¯ **å…·ä½“é—®é¢˜åˆ†æ**

### é—®é¢˜1: è¯­ä¹‰ç ´å
```python
# åŸå§‹å®ç°
z = torch.mean(hidden_states, dim=1)  # [batch_size, hidden_size]
attention_weights = self.excitation(z)  # [batch_size, hidden_size]
calibrated_states = attention_weights * hidden_states  # å¹¿æ’­ä¹˜æ³•
```

**é—®é¢˜**ï¼š
- å¯¹"I hate immigrants"å’Œ"I love immigrants"å¯èƒ½äº§ç”Ÿç›¸ä¼¼çš„å…¨å±€æƒé‡
- æ— æ³•åŒºåˆ†å…³é”®çš„æƒ…æ„Ÿè¯æ±‡å’Œèº«ä»½è¯æ±‡çš„ç»„åˆ
- ä¸¢å¤±äº†è¯æ±‡é—´çš„ç›¸å¯¹é‡è¦æ€§

### é—®é¢˜2: è¿‡åº¦æ­£åˆ™åŒ–
```python
# åŒé‡æ­£åˆ™åŒ–
enhanced_states = self.asrm(hidden_states)  # ASRMæ ¡å‡† (ç¬¬ä¸€å±‚æ­£åˆ™åŒ–)
pooled_output = self.dropout(cls_representation)  # Dropout (ç¬¬äºŒå±‚æ­£åˆ™åŒ–)
```

**é—®é¢˜**ï¼š
- ASRMæœ¬èº«å°±æ˜¯ä¸€ç§ç‰¹å¾é€‰æ‹©/æ­£åˆ™åŒ–
- å†åŠ ä¸Šdropouté€ æˆè¿‡åº¦æŠ‘åˆ¶
- æ¨¡å‹è¡¨è¾¾èƒ½åŠ›ä¸‹é™

### é—®é¢˜3: ç¼ºä¹å¯¹æ¯”å­¦ä¹ é€‚é…
```python
# å½“å‰ASRMåœ¨å¯¹æ¯”å­¦ä¹ ä¸­çš„ä½¿ç”¨
view1_features = self.asrm(bert_output)  # è§†å›¾1
view2_features = mask_augmented_output   # è§†å›¾2
```

**é—®é¢˜**ï¼š
- ASRMæ²¡æœ‰è€ƒè™‘å¯¹æ¯”å­¦ä¹ çš„ç‰¹æ®Šéœ€æ±‚
- æ²¡æœ‰å¢å¼ºæ ·æœ¬é—´çš„åŒºåˆ†åº¦
- å¯èƒ½ä½¿æ­£è´Ÿæ ·æœ¬å˜å¾—æ›´ç›¸ä¼¼

## ğŸ’¡ **ä¸ºä»€ä¹ˆDCLæœ‰æ•ˆè€ŒASRMæ— æ•ˆ**

### DCLçš„æˆåŠŸè¦ç´ ï¼š
1. **Span-levelå»ºæ¨¡**ï¼šå…³æ³¨è¯æ±‡ç»„åˆçš„è¯­ä¹‰
2. **åŒé‡å¯¹æ¯”**ï¼šè‡ªç›‘ç£+ç›‘ç£ï¼Œå¤šå±‚æ¬¡å­¦ä¹ 
3. **ç„¦ç‚¹æŸå¤±**ï¼šè§£å†³æ•°æ®ä¸å¹³è¡¡
4. **ä¿æŒå¤šæ ·æ€§**ï¼šå¢å¼ºè€Œéå‰Šå¼±ç‰¹å¾å·®å¼‚

### ASRMçš„å±€é™æ€§ï¼š
1. **Token-levelå»ºæ¨¡**ï¼šå¿½ç•¥äº†è¯­ä¹‰ç»„åˆ
2. **å•ä¸€æ ¡å‡†**ï¼šç¼ºä¹å¤šå±‚æ¬¡çš„è¯­ä¹‰ç†è§£
3. **ç»Ÿä¸€åŒ–å€¾å‘**ï¼šå‡å°‘è€Œéå¢å¼ºç‰¹å¾å·®å¼‚
4. **ä½ç½®æ— å…³**ï¼šä¸¢å¤±äº†åºåˆ—ç»“æ„ä¿¡æ¯

## ğŸ”§ **æ”¹è¿›æ–¹å‘**

### 1. **ä»Token-levelåˆ°Span-level**
```python
# æ”¹è¿›æ€è·¯ï¼šSpan-aware ASRM
class SpanAwareASRM(nn.Module):
    def __init__(self, hidden_size, window_sizes=[1, 3, 5]):
        # å¤šçª—å£å·ç§¯æ•è·ä¸åŒé•¿åº¦çš„span
        self.span_convs = nn.ModuleList([
            nn.Conv1d(hidden_size, hidden_size, kernel_size=ws, padding=ws//2)
            for ws in window_sizes
        ])
```

### 2. **ä½ç½®æ„ŸçŸ¥çš„æ ¡å‡†**
```python
# æ”¹è¿›æ€è·¯ï¼šPosition-awareæ ¡å‡†
class PositionAwareASRM(nn.Module):
    def forward(self, hidden_states, attention_mask):
        # è€ƒè™‘ä½ç½®ä¿¡æ¯çš„æ ¡å‡†
        position_weights = self.position_encoder(hidden_states)
        semantic_weights = self.semantic_encoder(hidden_states)
        return hidden_states * position_weights * semantic_weights
```

### 3. **å¯¹æ¯”å­¦ä¹ å‹å¥½çš„è®¾è®¡**
```python
# æ”¹è¿›æ€è·¯ï¼šContrastive-friendly ASRM
class ContrastiveASRM(nn.Module):
    def forward(self, hidden_states, labels=None):
        if self.training and labels is not None:
            # è®­ç»ƒæ—¶å¢å¼ºç±»é—´å·®å¼‚
            return self.enhance_inter_class_difference(hidden_states, labels)
        else:
            # æ¨ç†æ—¶ä¿æŒè¯­ä¹‰å®Œæ•´æ€§
            return self.preserve_semantics(hidden_states)
```

## ğŸ“Š **å®éªŒéªŒè¯å»ºè®®**

### 1. **æ¶ˆèå®éªŒ**
- æµ‹è¯•ç§»é™¤ASRMåçš„æ€§èƒ½
- æµ‹è¯•ä¸åŒæ ¡å‡†ç­–ç•¥çš„æ•ˆæœ
- å¯¹æ¯”token-level vs span-levelå»ºæ¨¡

### 2. **å¯è§†åŒ–åˆ†æ**
- è§‚å¯ŸASRMå‰åçš„æ³¨æ„åŠ›åˆ†å¸ƒ
- åˆ†æç‰¹å¾ç©ºé—´çš„å˜åŒ–
- æ£€æŸ¥æ ·æœ¬é—´çš„ç›¸ä¼¼åº¦å˜åŒ–

### 3. **å¯¹æ¯”å®éªŒ**
- BERTåŸºçº¿ vs BERT+ASRM
- åŸå§‹ASRM vs æ”¹è¿›ASRM
- å•ç‹¬ASRM vs é›†æˆDCLæ–¹æ³•

## ğŸ¯ **ç»“è®º**

ASRMä¸èµ·ä½œç”¨çš„æ ¹æœ¬åŸå› æ˜¯**è¯­ä¹‰å±‚æ¬¡ä¸åŒ¹é…**ï¼š
- DCLéœ€è¦çš„æ˜¯span-levelçš„è¯­ä¹‰ç†è§£
- ASRMæä¾›çš„æ˜¯token-levelçš„æƒé‡æ ¡å‡†
- å…¨å±€å¹³å‡æ± åŒ–ç ´åäº†å±€éƒ¨è¯­ä¹‰ç»“æ„
- ç»Ÿä¸€åŒ–çš„æ ¡å‡†å‰Šå¼±äº†ç‰¹å¾åˆ¤åˆ«æ€§

è¦è®©ASRMæœ‰æ•ˆï¼Œéœ€è¦ä»æ ¹æœ¬ä¸Šé‡æ–°è®¾è®¡ï¼Œä½¿å…¶èƒ½å¤Ÿï¼š
1. æ•è·span-levelçš„è¯­ä¹‰ä¿¡æ¯
2. ä¿æŒä½ç½®å’Œç»“æ„ä¿¡æ¯
3. å¢å¼ºè€Œéå‰Šå¼±ç‰¹å¾å·®å¼‚æ€§
4. é€‚é…å¯¹æ¯”å­¦ä¹ çš„ç‰¹æ®Šéœ€æ±‚

